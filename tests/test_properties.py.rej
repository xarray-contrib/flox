diff a/tests/test_properties.py b/tests/test_properties.py	(rejected hunks)
@@ -3,7 +3,9 @@ import pytest

 pytest.importorskip("hypothesis")
 pytest.importorskip("dask")
+pytest.importorskip("cftime")

+import cftime
 import dask
 import hypothesis.extra.numpy as npst
 import hypothesis.strategies as st
@@ -60,79 +62,60 @@ func_st = st.sampled_from(
     [f for f in ALL_FUNCS if f not in NON_NUMPY_FUNCS and f not in SKIPPED_FUNCS]
 )

+calendars = st.sampled_from(
+    [
+        "standard",
+        "gregorian",
+        "proleptic_gregorian",
+        "noleap",
+        "365_day",
+        "360_day",
+        "julian",
+        "all_leap",
+        "366_day",
+    ]
+)
+
+
+@st.composite
+def units(draw, *, calendar: str):
+    choices = ["days", "hours", "minutes", "seconds", "milliseconds", "microseconds"]
+    if calendar == "360_day":
+        choices += ["months"]
+    elif calendar == "noleap":
+        choices += ["common_years"]
+    time_units = draw(st.sampled_from(choices))
+
+    dt = draw(st.datetimes()).strftime("%Y-%m-%d")
+    if calendar == "360_day":
+        month %= 30
+    return f"{time_units} since {dt}"
+
+
+@st.composite
+def cftime_arrays(draw, *, calendars=calendars):
+    cal = draw(calendars)
+    values = draw(
+        npst.arrays(
+            dtype=np.int64,
+            shape=st.integers(min_value=1, max_value=20),
+            elements={"min_value": -10_000, "max_value": 10_000},
+        )
+    )
+    unit = draw(units(calendar=cal))
+    return cftime.num2date(values, units=unit, calendar=cal)
+

 def by_arrays(shape):
-    return npst.arrays(
-        dtype=npst.integer_dtypes(endianness="=") | npst.unicode_string_dtypes(endianness="="),
-        shape=shape,
+    return st.one_of(
+        # npst.arrays(
+        # dtype=npst.integer_dtypes(endianness="=") | npst.unicode_string_dtypes(endianness="="),
+        # shape=shape,
+        # ),
+        cftime_arrays(),
     )


-def not_overflowing_array(array) -> bool:
-    if array.dtype.kind == "f":
-        info = np.finfo(array.dtype)
-    elif array.dtype.kind in ["i", "u"]:
-        info = np.iinfo(array.dtype)  # type: ignore[assignment]
-    else:
-        return True
-
-    result = bool(np.all((array < info.max / array.size) & (array > info.min / array.size)))
-    # note(f"returning {result}, {array.min()} vs {info.min}, {array.max()} vs {info.max}")
-    return result
-
-
-@given(
-    array=npst.arrays(
-        elements={"allow_subnormal": False}, shape=npst.array_shapes(), dtype=array_dtype_st
-    ),
-    dtype=by_dtype_st,
-    func=func_st,
-)
-def test_groupby_reduce(array, dtype, func):
-    # overflow behaviour differs between bincount and sum (for example)
-    assume(not_overflowing_array(array))
-    # TODO: fix var for complex numbers upstream
-    assume(not (("quantile" in func or "var" in func or "std" in func) and array.dtype.kind == "c"))
-    # arg* with nans in array are weird
-    assume("arg" not in func and not np.any(np.isnan(array).ravel()))
-
-    axis = -1
-    by = np.ones((array.shape[-1],), dtype=dtype)
-    kwargs = {"q": 0.8} if "quantile" in func else {}
-    flox_kwargs = {}
-    with np.errstate(invalid="ignore", divide="ignore"):
-        actual, _ = groupby_reduce(
-            array, by, func=func, axis=axis, engine="numpy", **flox_kwargs, finalize_kwargs=kwargs
-        )
-
-        # numpy-groupies always does the calculation in float64
-        if (
-            ("var" in func or "std" in func or "sum" in func or "mean" in func)
-            and array.dtype.kind == "f"
-            and array.dtype.itemsize != 8
-        ):
-            # bincount always accumulates in float64,
-            # casting to float64 handles std more like npg does.
-            # Setting dtype=float64 works fine for sum, mean.
-            cast_to = array.dtype
-            array = array.astype(np.float64)
-            note(f"casting array to float64, cast_to={cast_to!r}")
-        else:
-            cast_to = None
-        note(("kwargs:", kwargs, "cast_to:", cast_to))
-        expected = getattr(np, func)(array, axis=axis, keepdims=True, **kwargs)
-        if cast_to is not None:
-            note(("casting to:", cast_to))
-            expected = expected.astype(cast_to)
-            actual = actual.astype(cast_to)
-
-    note(("expected: ", expected, "actual: ", actual))
-    tolerance = (
-        {"rtol": 1e-13, "atol": 1e-15} if "var" in func or "std" in func else {"atol": 1e-15}
-    )
-    assert_equal(expected, actual, tolerance)
-
-
 @st.composite
 def chunks(draw, *, shape: tuple[int, ...]) -> tuple[tuple[int, ...], ...]:
     chunks = []
@@ -177,6 +160,66 @@ def chunked_arrays(
     return from_array(array, chunks=chunks)


+def not_overflowing_array(array) -> bool:
+    if array.dtype.kind == "f":
+        info = np.finfo(array.dtype)
+    elif array.dtype.kind in ["i", "u"]:
+        info = np.iinfo(array.dtype)  # type: ignore[assignment]
+    else:
+        return True
+
+    result = bool(np.all((array < info.max / array.size) & (array > info.min / array.size)))
+    # note(f"returning {result}, {array.min()} vs {info.min}, {array.max()} vs {info.max}")
+    return result
+
+
+# TODO: migrate to by_arrays() but with constant value
+@given(array=numeric_arrays(), dtype=by_dtype_st, func=func_st)
+def test_groupby_reduce(array, dtype, func):
+    # overflow behaviour differs between bincount and sum (for example)
+    assume(not_overflowing_array(array))
+    # TODO: fix var for complex numbers upstream
+    assume(not (("quantile" in func or "var" in func or "std" in func) and array.dtype.kind == "c"))
+    # arg* with nans in array are weird
+    assume("arg" not in func and not np.any(np.isnan(array).ravel()))
+
+    axis = -1
+    by = np.ones((array.shape[-1],), dtype=dtype)
+    kwargs = {"q": 0.8} if "quantile" in func else {}
+    flox_kwargs = {}
+    with np.errstate(invalid="ignore", divide="ignore"):
+        actual, _ = groupby_reduce(
+            array, by, func=func, axis=axis, engine="numpy", **flox_kwargs, finalize_kwargs=kwargs
+        )
+
+        # numpy-groupies always does the calculation in float64
+        if (
+            ("var" in func or "std" in func or "sum" in func or "mean" in func)
+            and array.dtype.kind == "f"
+            and array.dtype.itemsize != 8
+        ):
+            # bincount always accumulates in float64,
+            # casting to float64 handles std more like npg does.
+            # Setting dtype=float64 works fine for sum, mean.
+            cast_to = array.dtype
+            array = array.astype(np.float64)
+            note(f"casting array to float64, cast_to={cast_to!r}")
+        else:
+            cast_to = None
+        note(("kwargs:", kwargs, "cast_to:", cast_to))
+        expected = getattr(np, func)(array, axis=axis, keepdims=True, **kwargs)
+        if cast_to is not None:
+            note(("casting to:", cast_to))
+            expected = expected.astype(cast_to)
+            actual = actual.astype(cast_to)
+
+    note(("expected: ", expected, "actual: ", actual))
+    tolerance = (
+        {"rtol": 1e-13, "atol": 1e-15} if "var" in func or "std" in func else {"atol": 1e-15}
+    )
+    assert_equal(expected, actual, tolerance)
+
+
 @given(
     data=st.data(),
     array=chunked_arrays(),
